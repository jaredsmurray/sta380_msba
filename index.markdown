---
# Feel free to add content and custom Front Matter to this file.
# To modify the layout, see https://jekyllrb.com/docs/themes/#overriding-theme-defaults

layout: home
---

# [Syllabus](files/syllabus.pdf)

# Contact and office hours

Please contact me via Canvas message (this helps me prioritize you in my inbox). Office hours will be via Zoom, this page will be updated with times and a link.

# Class Materials

### Textbook

[Introduction to Statistical Learning with Applications in R](https://www.statlearning.com/), with R code available [here](https://www.statlearning.com/resources-second-edition). Between this R code and the code accompanying lectures, you have plenty of examples to adapt for homework and projects!

### Datasets

Individual datasets are [here](https://github.com/jaredsmurray/sta380_msba/tree/main/data/), or you can download them all [here](data.zip).

### Section 1: Introduction

- [Slides](slides/01-Intro.pdf)
- [R code](R/Intro.R)

### Section 2: Tree Methods, Bagging, and Boosting

- [Slides](slides/02-Trees.pdf)
- [R code](R/Trees_MSBA.R), [California setup](R/cal_setup.txt), [BART example](R/BART_example.R)

### Section 3: Regression

- [Slides]()
- [R code]()

### Section 4: Classification

- [Slides]()
- [R code]()

### Section 5: (A Brief Intro To) Neural Nets

- [Slides]()
- [R code]()

### Class Recordings

Week 1: 7/15 7/16 7/17 7/18

Week 2: 7/22 7/23 7/24 7/25



# Assignments

- [Take-home problems](files/takehome.pdf). Start working on these early!
- [Individual prediction project (and contest!)](files/individual_project.pdf) Data: [austinhouses.csv](data/austinhouses.csv), [austinhouses_holdout.csv](data/austinhouses_holdout.csv)
- [Group project](files/group_project.pdf)

# R/Rstudio Resources

- [Rstudio](https://posit.co/download/rstudio-desktop/). A cross-platform IDE for writing R code.
- [Irizarry, "Introduction to Data Science (Data Wrangling and Visualization with R)"](https://rafalab.dfci.harvard.edu/dsbook-part-1/). An excellent reference for modern data science in R using the `ggplot2` and `tidyverse` libraries. 

# Additional Resources

This class is fast-paced, and intended to introduce you to key methods in supervised/predictive machine learning. If you want to go deeper, or learn about other methods and software, here are some additional resources:

- [Hastie, Tibshirani, and Friedman, "The Elements of Statistical Learning"](https://hastie.su.domains/ElemStatLearn/). A more advanced/theoretical version of the class text.
- [Kuhn, "The `caret` package" ](https://topepo.github.io/caret/index.html). In class we will explore various ML methods as implemnted in individual R packages. The `caret` package provides a standardized interface to these methods (and more) that makes it easier to standardize data, do train/test splits, and train/tune/compare/ensemble models.
- [Molnar, "Interpretable Machine Learning"](https://christophm.github.io/interpretable-ml-book/). An accessible review of methods for "interpreting" or "explaining" how ML methods use data to make predictions. Terms like "interpretability"" and "explainability" aren't always defined the same by different authors, and are in some ways trying to solve an ill-posed problem. This book provides a fairly comprehensive review of methods with examples and discussion of their pros and cons.
- [scikit-learn](https://scikit-learn.org/stable/index.html) Popular Python library for machine learning. Your textbook also has a Python equivalent at the same site linked above. Once you're familiar with the methods themselves, moving between languages is (in general) pretty easy!







